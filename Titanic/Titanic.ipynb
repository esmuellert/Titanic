{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "J_theta: 0.7618145\n",
      "0.63829786\n",
      "\n",
      "\n",
      "1000\n",
      "J_theta: 0.43892616\n",
      "0.83687943\n",
      "\n",
      "\n",
      "2000\n",
      "J_theta: 0.43614057\n",
      "0.83687943\n",
      "\n",
      "\n",
      "3000\n",
      "J_theta: 0.4345359\n",
      "0.83687943\n",
      "\n",
      "\n",
      "4000\n",
      "J_theta: 0.43251747\n",
      "0.8439716\n",
      "\n",
      "\n",
      "5000\n",
      "J_theta: 0.43207785\n",
      "0.8439716\n",
      "\n",
      "\n",
      "6000\n",
      "J_theta: 0.431031\n",
      "0.858156\n",
      "\n",
      "\n",
      "7000\n",
      "J_theta: 0.43057042\n",
      "0.858156\n",
      "\n",
      "\n",
      "8000\n",
      "J_theta: 0.43046874\n",
      "0.858156\n",
      "\n",
      "\n",
      "9000\n",
      "J_theta: 0.43041688\n",
      "0.858156\n",
      "\n",
      "\n",
      "10000\n",
      "J_theta: 0.43038914\n",
      "0.858156\n",
      "\n",
      "\n",
      "11000\n",
      "J_theta: 0.43037358\n",
      "0.858156\n",
      "\n",
      "\n",
      "12000\n",
      "J_theta: 0.43036357\n",
      "0.858156\n",
      "\n",
      "\n",
      "13000\n",
      "J_theta: 0.43035606\n",
      "0.858156\n",
      "\n",
      "\n",
      "14000\n",
      "J_theta: 0.43035153\n",
      "0.858156\n",
      "\n",
      "\n",
      "15000\n",
      "J_theta: 0.43034753\n",
      "0.858156\n",
      "\n",
      "\n",
      "16000\n",
      "J_theta: 0.4303447\n",
      "0.858156\n",
      "\n",
      "\n",
      "17000\n",
      "J_theta: 0.43034214\n",
      "0.858156\n",
      "\n",
      "\n",
      "18000\n",
      "J_theta: 0.43034112\n",
      "0.858156\n",
      "\n",
      "\n",
      "19000\n",
      "J_theta: 0.43033862\n",
      "0.858156\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get data from train_1.csv\n",
    "tmp = np.genfromtxt(\"train_3.csv\", dtype=float, delimiter=\",\")\n",
    "\n",
    "# set training_data quantity and validation data quantity\n",
    "train_quantity = 750\n",
    "validation_quantity = 891-train_quantity\n",
    "\n",
    "# 归一化\n",
    "tem = tmp[1:,3:]\n",
    "ave = np.mean(tem,axis = 0)*np.ones((891,5))\n",
    "ptp = np.ptp(tem,axis = 0)*np.ones((891,5))\n",
    "tem = np.subtract(tem,ave)\n",
    "tem = np.true_divide(tem,ptp)\n",
    "tmp[1:,3:] = tem\n",
    "\n",
    "#apart train,validation\n",
    "train_data = tmp[1:train_quantity+1,3:]\n",
    "validation_data0 = tmp[train_quantity+1:,3:]\n",
    "\n",
    "train_lable = tmp[1:train_quantity+1,2]\n",
    "validation_lable0 = tmp[train_quantity+1:,2]\n",
    "\n",
    "train_lable = train_lable.reshape(train_quantity,1)\n",
    "validation_lable0 = validation_lable0.reshape(validation_quantity,1)\n",
    "\n",
    "# define layer function\n",
    "def add_layer(input,in_size,out_size):\n",
    "    theta = tf.Variable(tf.random_normal([in_size,out_size]))\n",
    "    if out_size==1:\n",
    "        z = tf.matmul(input,theta)\n",
    "        a = tf.sigmoid(z)\n",
    "    else:\n",
    "        z = tf.matmul(input,theta)\n",
    "        a = tf.nn.relu(z)\n",
    "        a_0 = tf.ones([train_quantity,1])\n",
    "        a = tf.concat([a_0,a],1)\n",
    "    return theta,a,z\n",
    "\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32,[None,5])\n",
    "ys = tf.placeholder(tf.float32,[None,1])\n",
    "\n",
    "# add hidden layer\n",
    "theta_1,l1,z_1 = add_layer(xs,5,8)\n",
    "# add output layer\n",
    "theta_2,output,z_2 = add_layer(l1,9,1)\n",
    "\n",
    "#regularzation\n",
    "lamda = 0.13\n",
    "regularzation = (tf.reduce_sum(tf.square(theta_1))+tf.reduce_sum(tf.square(theta_2)))*lamda/600\n",
    "\n",
    "# the error between prediction and real data\n",
    "J_theta = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = ys,logits = z_2)) + regularzation\n",
    "\n",
    "a =  0.5\n",
    "# learning rate\n",
    "train_step = tf.train.GradientDescentOptimizer(a).minimize(J_theta)\n",
    "\n",
    "#prediction\n",
    "validation_data = tf.constant(validation_data0,tf.float32)\n",
    "validation_lable = tf.constant(validation_lable0,tf.float32)\n",
    "\n",
    "a_1 = tf.nn.relu(tf.matmul(validation_data,theta_1))\n",
    "a_0 = tf.ones([validation_quantity,1])\n",
    "a_20 = tf.concat([a_0,a_1],1)\n",
    "a_2 = tf.sigmoid(tf.matmul(a_20,theta_2))\n",
    "prediction = tf.round(a_2)\n",
    "\n",
    "validation = tf.subtract(prediction,validation_lable)\n",
    "validation = tf.abs(validation)\n",
    "accuracy =tf.reduce_sum(validation) \n",
    "accuracy = (validation_quantity-accuracy)/validation_quantity\n",
    "\n",
    "#initialize\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(20000):\n",
    "    #training\n",
    "    sess.run(train_step,feed_dict={xs:train_data,ys:train_lable})\n",
    "    \n",
    "    if i%1000 == 0:\n",
    "        loss = sess.run(J_theta,feed_dict={xs:train_data,ys:train_lable})\n",
    "        print(i)\n",
    "        print(\"J_theta:\",loss)\n",
    "        acc = sess.run(accuracy)\n",
    "        print(acc)\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import test sets\n",
    "test = np.genfromtxt(\"test_3.csv\",dtype = float,delimiter=\",\")\n",
    "\n",
    "#reshape test sets\n",
    "tem1 = test[1:,2:]\n",
    "ave1 = np.mean(tem1,axis = 0)*np.ones((418,5))\n",
    "ptp1 = np.ptp(tem1,axis = 0)*np.ones((418,5))\n",
    "tem1 = np.subtract(tem1,ave1)\n",
    "tem1 = np.true_divide(tem1,ptp1)\n",
    "test[1:,2:] = tem1\n",
    "test = test[1:,2:]\n",
    "\n",
    "# define tensorflow constant test data\n",
    "test_data = tf.constant(test,tf.float32)\n",
    "\n",
    "# predict test data\n",
    "t_1 = tf.nn.relu(tf.matmul(test_data,theta_1))\n",
    "t_0 = tf.ones([418,1])\n",
    "t_20 = tf.concat([t_0,t_1],1)\n",
    "t_2 = tf.sigmoid(tf.matmul(t_20,theta_2))\n",
    "prediction_1 = tf.round(t_2)\n",
    "prediction_1 = tf.to_int32(prediction_1)\n",
    "\n",
    "# return result\n",
    "result = sess.run(prediction_1)\n",
    "No = np.arange(892,1310)\n",
    "No = No.reshape(418,1)\n",
    "title = np.array([\"PassengerId\",\"Survived\"])\n",
    "title = title.reshape(1,2)\n",
    "result = np.append(No,result,axis=1)\n",
    "result = np.append(title,result,axis=0)\n",
    "np.savetxt(\"result.csv\", result, delimiter=\",\",fmt = \"%s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07828485],\n",
       "       [0.41773424],\n",
       "       [0.05639753],\n",
       "       [0.11642826],\n",
       "       [0.36232808],\n",
       "       [0.12406512],\n",
       "       [0.586018  ],\n",
       "       [0.17196302],\n",
       "       [0.7865508 ],\n",
       "       [0.11544763],\n",
       "       [0.11619608],\n",
       "       [0.26725817],\n",
       "       [0.9605941 ],\n",
       "       [0.10153506],\n",
       "       [0.96647125],\n",
       "       [0.9813595 ],\n",
       "       [0.11229893],\n",
       "       [0.3692417 ],\n",
       "       [0.38864338],\n",
       "       [0.7710768 ],\n",
       "       [0.22369397],\n",
       "       [0.15070243],\n",
       "       [0.97509944],\n",
       "       [0.56642   ],\n",
       "       [0.9337672 ],\n",
       "       [0.0673252 ],\n",
       "       [0.9977679 ],\n",
       "       [0.33428943],\n",
       "       [0.30294117],\n",
       "       [0.16674225],\n",
       "       [0.09558524],\n",
       "       [0.1932588 ],\n",
       "       [0.35498488],\n",
       "       [0.3421932 ],\n",
       "       [0.4470215 ],\n",
       "       [0.4304812 ],\n",
       "       [0.39208424],\n",
       "       [0.3714012 ],\n",
       "       [0.11654937],\n",
       "       [0.11125229],\n",
       "       [0.08005501],\n",
       "       [0.3886877 ],\n",
       "       [0.08873551],\n",
       "       [0.88742965],\n",
       "       [0.9698492 ],\n",
       "       [0.11671314],\n",
       "       [0.3003355 ],\n",
       "       [0.09205667],\n",
       "       [0.96766   ],\n",
       "       [0.3738502 ],\n",
       "       [0.44218045],\n",
       "       [0.30772364],\n",
       "       [0.86354977],\n",
       "       [0.8908817 ],\n",
       "       [0.24608949],\n",
       "       [0.27632055],\n",
       "       [0.10699365],\n",
       "       [0.11674177],\n",
       "       [0.11534833],\n",
       "       [0.95688546],\n",
       "       [0.11755252],\n",
       "       [0.11755466],\n",
       "       [0.11746295],\n",
       "       [0.5751711 ],\n",
       "       [0.731475  ],\n",
       "       [0.87546986],\n",
       "       [0.5693559 ],\n",
       "       [0.26166624],\n",
       "       [0.50308836],\n",
       "       [0.9576359 ],\n",
       "       [0.57772326],\n",
       "       [0.11713371],\n",
       "       [0.39121315],\n",
       "       [0.5470425 ],\n",
       "       [0.9722652 ],\n",
       "       [0.43990853],\n",
       "       [0.11618009],\n",
       "       [0.9752794 ],\n",
       "       [0.13252252],\n",
       "       [0.57772326],\n",
       "       [0.70920575],\n",
       "       [0.2529223 ],\n",
       "       [0.2473598 ],\n",
       "       [0.11619608],\n",
       "       [0.15535837],\n",
       "       [0.17765239],\n",
       "       [0.58123237],\n",
       "       [0.3650509 ],\n",
       "       [0.58560884],\n",
       "       [0.5011942 ],\n",
       "       [0.35709924],\n",
       "       [0.11620861],\n",
       "       [0.97021604],\n",
       "       [0.11618009],\n",
       "       [0.60536623],\n",
       "       [0.11672659],\n",
       "       [0.96227354],\n",
       "       [0.11629689],\n",
       "       [0.37126267],\n",
       "       [0.11380336],\n",
       "       [0.99159217],\n",
       "       [0.16156994],\n",
       "       [0.09205667],\n",
       "       [0.11662458],\n",
       "       [0.8081157 ],\n",
       "       [0.11489363],\n",
       "       [0.1695618 ],\n",
       "       [0.09205667],\n",
       "       [0.11611146],\n",
       "       [0.2524226 ],\n",
       "       [0.09731322],\n",
       "       [0.58550984],\n",
       "       [0.99595   ],\n",
       "       [0.5720555 ],\n",
       "       [0.9631423 ],\n",
       "       [0.42425695],\n",
       "       [0.19040422],\n",
       "       [0.41280028],\n",
       "       [0.38888258],\n",
       "       [0.8665713 ],\n",
       "       [0.8684934 ],\n",
       "       [0.09205667],\n",
       "       [0.99493223],\n",
       "       [0.11647094],\n",
       "       [0.09205667],\n",
       "       [0.33652487],\n",
       "       [0.11703961],\n",
       "       [0.5323222 ],\n",
       "       [0.09064129],\n",
       "       [0.11680438],\n",
       "       [0.11597265],\n",
       "       [0.23565783],\n",
       "       [0.33588466],\n",
       "       [0.19040422],\n",
       "       [0.08331135],\n",
       "       [0.11682478],\n",
       "       [0.25014257],\n",
       "       [0.16756625],\n",
       "       [0.3790366 ],\n",
       "       [0.09737158],\n",
       "       [0.27372718],\n",
       "       [0.9206832 ],\n",
       "       [0.19880281],\n",
       "       [0.15244411],\n",
       "       [0.29536006],\n",
       "       [0.11504982],\n",
       "       [0.3908807 ],\n",
       "       [0.11701311],\n",
       "       [0.3886877 ],\n",
       "       [0.13546368],\n",
       "       [0.9969765 ],\n",
       "       [0.18803354],\n",
       "       [0.04952269],\n",
       "       [0.38607264],\n",
       "       [0.12476426],\n",
       "       [0.11685644],\n",
       "       [0.9003208 ],\n",
       "       [0.37968567],\n",
       "       [0.29536006],\n",
       "       [0.36816832],\n",
       "       [0.58566535],\n",
       "       [0.6890863 ],\n",
       "       [0.8836026 ],\n",
       "       [0.11628897],\n",
       "       [0.09006786],\n",
       "       [0.34180778],\n",
       "       [0.2769747 ],\n",
       "       [0.11470543],\n",
       "       [0.99740344],\n",
       "       [0.3732123 ],\n",
       "       [0.11623192],\n",
       "       [0.2406759 ],\n",
       "       [0.11630045],\n",
       "       [0.18911436],\n",
       "       [0.09502816],\n",
       "       [0.8288888 ],\n",
       "       [0.83865154],\n",
       "       [0.23060659],\n",
       "       [0.8496643 ],\n",
       "       [0.9610655 ],\n",
       "       [0.13252252],\n",
       "       [0.3800175 ],\n",
       "       [0.97742903],\n",
       "       [0.09205667],\n",
       "       [0.9690131 ],\n",
       "       [0.08940754],\n",
       "       [0.86776894],\n",
       "       [0.11753637],\n",
       "       [0.21465872],\n",
       "       [0.08911151],\n",
       "       [0.10627654],\n",
       "       [0.38864008],\n",
       "       [0.13522549],\n",
       "       [0.05631236],\n",
       "       [0.42844594],\n",
       "       [0.11376905],\n",
       "       [0.78456485],\n",
       "       [0.3659489 ],\n",
       "       [0.19766498],\n",
       "       [0.39187628],\n",
       "       [0.55913585],\n",
       "       [0.20193824],\n",
       "       [0.3031077 ],\n",
       "       [0.86574847],\n",
       "       [0.17669758],\n",
       "       [0.52763486],\n",
       "       [0.5921469 ],\n",
       "       [0.18695503],\n",
       "       [0.9968278 ],\n",
       "       [0.11671618],\n",
       "       [0.11448306],\n",
       "       [0.11628378],\n",
       "       [0.29643705],\n",
       "       [0.87461185],\n",
       "       [0.40335357],\n",
       "       [0.29657072],\n",
       "       [0.5851711 ],\n",
       "       [0.23957635],\n",
       "       [0.92776674],\n",
       "       [0.11618009],\n",
       "       [0.98045886],\n",
       "       [0.11711758],\n",
       "       [0.88486755],\n",
       "       [0.11714415],\n",
       "       [0.98804384],\n",
       "       [0.7352486 ],\n",
       "       [0.11693521],\n",
       "       [0.58560884],\n",
       "       [0.09118066],\n",
       "       [0.09594417],\n",
       "       [0.33814082],\n",
       "       [0.98269904],\n",
       "       [0.11727992],\n",
       "       [0.09206883],\n",
       "       [0.35943675],\n",
       "       [0.11724264],\n",
       "       [0.1668326 ],\n",
       "       [0.3933576 ],\n",
       "       [0.87792945],\n",
       "       [0.97945076],\n",
       "       [0.9863129 ],\n",
       "       [0.8663927 ],\n",
       "       [0.31110084],\n",
       "       [0.11619696],\n",
       "       [0.17548037],\n",
       "       [0.3045869 ],\n",
       "       [0.8686442 ],\n",
       "       [0.09280789],\n",
       "       [0.8665713 ],\n",
       "       [0.737394  ],\n",
       "       [0.8890772 ],\n",
       "       [0.11723525],\n",
       "       [0.48376417],\n",
       "       [0.11667167],\n",
       "       [0.11569207],\n",
       "       [0.11623192],\n",
       "       [0.09205667],\n",
       "       [0.11638787],\n",
       "       [0.87874675],\n",
       "       [0.11714632],\n",
       "       [0.10366704],\n",
       "       [0.11713802],\n",
       "       [0.87145996],\n",
       "       [0.42676944],\n",
       "       [0.25119644],\n",
       "       [0.11619608],\n",
       "       [0.38639224],\n",
       "       [0.11623192],\n",
       "       [0.39208424],\n",
       "       [0.11747227],\n",
       "       [0.2963055 ],\n",
       "       [0.09205667],\n",
       "       [0.99328494],\n",
       "       [0.55913585],\n",
       "       [0.18912119],\n",
       "       [0.85840917],\n",
       "       [0.1485802 ],\n",
       "       [0.09040084],\n",
       "       [0.13432601],\n",
       "       [0.20883086],\n",
       "       [0.377009  ],\n",
       "       [0.19920327],\n",
       "       [0.58560884],\n",
       "       [0.86801463],\n",
       "       [0.39564127],\n",
       "       [0.10363327],\n",
       "       [0.11626302],\n",
       "       [0.4441819 ],\n",
       "       [0.18911436],\n",
       "       [0.11618009],\n",
       "       [0.38981774],\n",
       "       [0.5883162 ],\n",
       "       [0.18911436],\n",
       "       [0.22408074],\n",
       "       [0.10399696],\n",
       "       [0.11661199],\n",
       "       [0.9902408 ],\n",
       "       [0.16674225],\n",
       "       [0.39032903],\n",
       "       [0.11630424],\n",
       "       [0.11600113],\n",
       "       [0.24704272],\n",
       "       [0.09195396],\n",
       "       [0.1167406 ],\n",
       "       [0.58560884],\n",
       "       [0.969014  ],\n",
       "       [0.39955977],\n",
       "       [0.1998218 ],\n",
       "       [0.22494423],\n",
       "       [0.39123774],\n",
       "       [0.1173675 ],\n",
       "       [0.34576157],\n",
       "       [0.11622936],\n",
       "       [0.5947531 ],\n",
       "       [0.95556664],\n",
       "       [0.56853074],\n",
       "       [0.21675295],\n",
       "       [0.24506825],\n",
       "       [0.11651222],\n",
       "       [0.21567656],\n",
       "       [0.11662458],\n",
       "       [0.27998826],\n",
       "       [0.16756625],\n",
       "       [0.36424264],\n",
       "       [0.9282904 ],\n",
       "       [0.11701296],\n",
       "       [0.8256097 ],\n",
       "       [0.29670522],\n",
       "       [0.14374538],\n",
       "       [0.22129303],\n",
       "       [0.8553048 ],\n",
       "       [0.36917946],\n",
       "       [0.18912119],\n",
       "       [0.75332075],\n",
       "       [0.1165079 ],\n",
       "       [0.38864008],\n",
       "       [0.11745358],\n",
       "       [0.08501855],\n",
       "       [0.18273325],\n",
       "       [0.762927  ],\n",
       "       [0.25805068],\n",
       "       [0.11602139],\n",
       "       [0.10995608],\n",
       "       [0.9192082 ],\n",
       "       [0.17763245],\n",
       "       [0.36081612],\n",
       "       [0.16756625],\n",
       "       [0.7643241 ],\n",
       "       [0.18784578],\n",
       "       [0.8763013 ],\n",
       "       [0.9895181 ],\n",
       "       [0.17669758],\n",
       "       [0.2822581 ],\n",
       "       [0.09971386],\n",
       "       [0.40667722],\n",
       "       [0.24095242],\n",
       "       [0.96452224],\n",
       "       [0.11619781],\n",
       "       [0.09205667],\n",
       "       [0.36743048],\n",
       "       [0.11149897],\n",
       "       [0.9788592 ],\n",
       "       [0.8763013 ],\n",
       "       [0.11642826],\n",
       "       [0.997465  ],\n",
       "       [0.21465872],\n",
       "       [0.17764603],\n",
       "       [0.2786747 ],\n",
       "       [0.98996824],\n",
       "       [0.26857942],\n",
       "       [0.22078948],\n",
       "       [0.9908744 ],\n",
       "       [0.24560082],\n",
       "       [0.09149433],\n",
       "       [0.9617002 ],\n",
       "       [0.9410391 ],\n",
       "       [0.37420088],\n",
       "       [0.22078948],\n",
       "       [0.21650106],\n",
       "       [0.16749635],\n",
       "       [0.09205667],\n",
       "       [0.12110949],\n",
       "       [0.37084383],\n",
       "       [0.3418925 ],\n",
       "       [0.1324945 ],\n",
       "       [0.7814883 ],\n",
       "       [0.11683303],\n",
       "       [0.09721683],\n",
       "       [0.1696675 ],\n",
       "       [0.16389976],\n",
       "       [0.45378393],\n",
       "       [0.9741489 ],\n",
       "       [0.12678973],\n",
       "       [0.09250712],\n",
       "       [0.11484216],\n",
       "       [0.9751992 ],\n",
       "       [0.13831688],\n",
       "       [0.98477143],\n",
       "       [0.1170418 ],\n",
       "       [0.08746889],\n",
       "       [0.9111053 ],\n",
       "       [0.09311546],\n",
       "       [0.9978313 ],\n",
       "       [0.5015088 ],\n",
       "       [0.31776312],\n",
       "       [0.4847186 ],\n",
       "       [0.19766498],\n",
       "       [0.27604187],\n",
       "       [0.5857077 ],\n",
       "       [0.4088878 ],\n",
       "       [0.58560884],\n",
       "       [0.98114383],\n",
       "       [0.39042574],\n",
       "       [0.11618009],\n",
       "       [0.9883286 ],\n",
       "       [0.09588096],\n",
       "       [0.11618009],\n",
       "       [0.73236746]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(t_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
